# Measuring and Mitigating Bias in Sentiment Classification
 
In this study, the bias produced in sentiment classification for a collection of Tweets is investigated across various machine learning models. The scripts used to process data set and measure bias produced by various machine learning models are attached as Jupyter Notebooks.

## Data Set
The data set is **Not** included in the folder, please place the data files to corresponding folders before running the scripts. The `train` and `dev` data with noise phrases removed need to be generated by running the `reduce noise.ipynb`.

## Machine Learning Models
There are four classifiers explored in this work and are listed below:
1. K-Nearest Neighbour Classifier (*KNN*) - `KNN classifier.ipynb`
2. Gaussian Na ̈ıve Bayes Classifier (*NB*) - `NB classifier.ipynb`
3. Logistic Regression Classifier (*LR*) - `LR classifier.ipynb`
4. Multilayer Perceptron Classifier (*MLP*) - `MLP classifier.ipynb`

Each classifier has a corresponding Jupyter Notebook which contains several sections:
- Load data
- Train model
- Prediction
- Bias evaluation
    - Accuracy
    - Selection rate + Demographic parity difference
    - Error Rate Equality Difference
- Bias mitigation
    - Noise phrases removed
    - Exponentiated Gradient (NB + LR)

## Data Processing
Some helper scripts are used to process or analyse the data set:
1. `check balance.ipynb`
    - Check the balance in the given date set
1. `noise analysis.ipynb`
    - Filter and count the noise phrases for each demographic group
1. `reduce noise.ipynb`
    - Remove the noise phrases identified
    - Re-generate text embeddings (SBERT)
    - Store the filtered data as pickle files
1. `word frequency.ipynb`
    - Find the most frequent words in the data set
    - Check the distribution of certain words between demographic groups

## References
Scripts use existing machine learning models from *Scikit-learn* library with customised parameters. 

Bias evaluation metrics including `Selection rate`, `Demographic parity difference` are from *Fairlearn*.

Bias mitigation techniques like `Exponentiated Gradient Reduction` is experimented and it's also from *Fairlearn*.